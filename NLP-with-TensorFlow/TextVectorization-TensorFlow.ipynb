{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9Zzm5eyUjAAYeJXfTbxU+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TirendazAcademy/Deep-Learning-with-TensorFlow/blob/main/TextVectorization-TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to the TextVectorization Layer in TensorFLow"
      ],
      "metadata": {
        "id": "BtCRHk7d9pMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This video walks you through how to use the TextVectorization layer in TensorFlow"
      ],
      "metadata": {
        "id": "yV3XfcjY7Vb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "5pyat2_2uojp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanting\n",
        "text_vectorization = TextVectorization()"
      ],
      "metadata": {
        "id": "L3RsgOluyiyU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    \"Bugün hava çok güzel\",\n",
        "    \"Ali, Efe ve Ece çay içecek\",\n",
        "    \"Selam söyle\"\n",
        "]"
      ],
      "metadata": {
        "id": "iY8S5onGytHD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the vocabulary with the adapt method.\n",
        "text_vectorization.adapt(data)"
      ],
      "metadata": {
        "id": "4ngXk1j4zCbb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at the vocabulary.\n",
        "text_vectorization.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05I_y-XVzKDl",
        "outputId": "3a62d4aa-b4f2-4d50-cced-b6f61fb1b09e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'çok',\n",
              " 'çay',\n",
              " 've',\n",
              " 'söyle',\n",
              " 'selam',\n",
              " 'içecek',\n",
              " 'hava',\n",
              " 'güzel',\n",
              " 'efe',\n",
              " 'ece',\n",
              " 'bugün',\n",
              " 'ali']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing with the layer\n",
        "vectorized_text = text_vectorization(data)\n",
        "vectorized_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEdicTg-zTQj",
        "outputId": "5a7a8e1e-31ca-4e50-fbd5-b996193eb0a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 6), dtype=int64, numpy=\n",
              "array([[12,  8,  2,  9,  0,  0],\n",
              "       [13, 10,  4, 11,  3,  7],\n",
              "       [ 6,  5,  0,  0,  0,  0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the custom functions TextVectorization"
      ],
      "metadata": {
        "id": "uDU2o1dl7jI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string"
      ],
      "metadata": {
        "id": "BGgSQArYzpvE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardization_fn(string_tensor):\n",
        "  lowercase=tf.strings.lower(string_tensor)\n",
        "  return tf.strings.regex_replace(\n",
        "      lowercase, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
        "  )"
      ],
      "metadata": {
        "id": "aIx40gV406yD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_fn(string_tensor):\n",
        "  return tf.strings.split(string_tensor)"
      ],
      "metadata": {
        "id": "4T19MwA42RSq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    standardize=standardization_fn,\n",
        "    split = split_fn\n",
        ")"
      ],
      "metadata": {
        "id": "LwuWFbHC2qKT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.adapt(data)"
      ],
      "metadata": {
        "id": "GUlD9_573H9K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing our layer with a text\n",
        "text = \"bugün ece çok güzel\"\n",
        "text_vectorization(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXmh5k_s3P_s",
        "outputId": "ba39b903-e28b-412e-fa10-53112277cee4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([12, 11,  2,  9])>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using TextVectorization in a model"
      ],
      "metadata": {
        "id": "YbTuG4QN8jtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Dataset object\n",
        "text_dataset = tf.data.Dataset.from_tensor_slices([\n",
        "    \"kedi\", \"aslan\", \"yunus\"\n",
        "])"
      ],
      "metadata": {
        "id": "BPDzXpJW3wIq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the TextVectorization layer\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=5000,\n",
        "    output_sequence_length=4\n",
        ")"
      ],
      "metadata": {
        "id": "PB6sAoHf4Ydq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the vocabulary\n",
        "vectorize_layer.adapt(text_dataset.batch(64))"
      ],
      "metadata": {
        "id": "5mqlU58R40P-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sIxlLm-5RYq",
        "outputId": "1158826e-0f5c-427a-d143-25d2a7b7a895"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'yunus', 'kedi', 'aslan']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
        "    vectorize_layer\n",
        "])"
      ],
      "metadata": {
        "id": "nAMORijK5WTC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting a data for testing\n",
        "input_data=[[\"kedi kartal aslan\"], [\"fok yunus\"]]"
      ],
      "metadata": {
        "id": "ZtqlDmjY5vx7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mISY78tN6AfL",
        "outputId": "711c2821-cc29-42c0-e991-9753fde97f92"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 310ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 1, 4, 0],\n",
              "       [1, 2, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's connect [YouTube](http://youtube.com/tirendazacademy) | [Medium](http://tirendazacademy.medium.com) | [Twitter](http://twitter.com/tirendazacademy) | [Instagram](https://www.instagram.com/tirendazacademy)"
      ],
      "metadata": {
        "id": "z7TWFm4B87Vs"
      }
    }
  ]
}